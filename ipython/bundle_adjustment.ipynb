{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large-scale bundle adjustment in scipy\n",
    "\n",
    "TAGS: Optimization and fitting\n",
    "\n",
    "AUTHORS: Nikolay Mayorov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bundle adjusmtent problem arises in 3-D reconstruction and it can be formulated as follows (taken from https://en.wikipedia.org/wiki/Bundle_adjustment):\n",
    "\n",
    "> Given a set of images depicting a number of 3D points from different viewpoints, bundle adjustment can be defined as the problem of simultaneously refining the 3D coordinates describing the scene geometry as well as the parameters of the relative motion and the optical characteristics of the camera(s) employed to acquire the images, according to an optimality criterion involving the corresponding image projections of all points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More precisely. We have a set of points in real world defined by their coordinates $(X, Y, Z)$ in some apriori chosen \"world coordinate frame\". We photograph these points by different cameras, which are characterized by their orientation and translation relative to the world coordinate frame and also by focal length and two radial distortion parameters (9 parameters in total). Then we precicely measure 2-D coordinates $(x, y)$ of the points projected by the cameras on images. Our task is to refine 3-D coordinates of original points as well as camera parameters by minimizing the sum of squares of reprojecting errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\pmb{P} = (X, Y, Z)^T$ - a radius-vector of a point, $\\pmb{R}$ - a rotation matrix of a camera, $\\pmb{t}$ - a translation vector of a camera, $f$ - its focal distance in pixels, $k_1, k_2$ - its distortion parameters. Then the reprojecting is done as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\pmb{Q} = \\pmb{R} \\pmb{P} + \\pmb{t} \\\\\n",
    "\\pmb{q} = -\\begin{pmatrix} Q_x / Q_z \\\\ Q_y / Q_z \\end{pmatrix} \\\\\n",
    "\\pmb{p} = f (1 + k_1 \\lVert \\pmb{q} \\rVert^2 + k_2 \\lVert \\pmb{q} \\rVert^4) \\pmb{q}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting vector $\\pmb{p}=(x, y)^T$ contains image coordinates of the original point.\n",
    "This model is called \"pinhole camera model\", you can read more about it here http://www.comp.nus.edu.sg/~cs4243/lecture/camera.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional notes regarding the formulas above:\n",
    "    \n",
    "1. $\\pmb{R}$ is the rotation matrix which projects from the world axes to the camera axes.\n",
    "2. $\\pmb{t}$ is the translation vector from the camera origin to the world origin expressed in the camera axes.\n",
    "3. The minus sign for $\\pmb{q}$ accounts for a particular camera axes convention: $x$ points right, $y$ points up and $z$ points backwards such that observed points have negative $z$ values. Usually $y$ and $z$ directions are chosen to be the opposite, but here we stick with the convention used in BAL dataset (see next).\n",
    "4. The components of $\\pmb{p}$ are pixel coordinates with $(0, 0)^T$ being the image center. Usually the pixel coordinates origin is chosen to be at the top left corner of an image and the image center parameters $c_x, c_y$ are considered or estimated. But here we stick with the convention used in BAL dataset where center parameters are not explicitly modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera position $\\pmb{t}'$ and rotation $\\pmb{R}'$ relative to the world frame can be computed from $\\pmb{R}, \\pmb{t}$ as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\pmb{t}' = -\\pmb{R}^T t \\\\\n",
    "\\pmb{R}' = \\pmb{R}^T\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's solve a real bundle adjusment problem from BAL dataset: http://grail.cs.washington.edu/projects/bal/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import bz2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://grail.cs.washington.edu/projects/bal/data/ladybug/\"\n",
    "FILE_NAME = \"problem-49-7776-pre.txt.bz2\"\n",
    "URL = BASE_URL + FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(FILE_NAME):\n",
    "    urllib.request.urlretrieve(URL, FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read the data from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bal_data(file_name):\n",
    "    with bz2.open(file_name, \"rt\") as file:\n",
    "        n_cameras, n_points, n_observations = map(\n",
    "            int, file.readline().split())\n",
    "\n",
    "        camera_indices = np.empty(n_observations, dtype=int)\n",
    "        point_indices = np.empty(n_observations, dtype=int)\n",
    "        points_2d = np.empty((n_observations, 2))\n",
    "\n",
    "        for i in range(n_observations):\n",
    "            camera_index, point_index, x, y = file.readline().split()\n",
    "            camera_indices[i] = int(camera_index)\n",
    "            point_indices[i] = int(point_index)\n",
    "            points_2d[i] = [float(x), float(y)]\n",
    "\n",
    "        camera_params = np.empty(n_cameras * 9)\n",
    "        for i in range(n_cameras * 9):\n",
    "            camera_params[i] = float(file.readline())\n",
    "        camera_params = camera_params.reshape((n_cameras, -1))\n",
    "\n",
    "        points_3d = np.empty(n_points * 3)\n",
    "        for i in range(n_points * 3):\n",
    "            points_3d[i] = float(file.readline())\n",
    "        points_3d = points_3d.reshape((n_points, -1))\n",
    "\n",
    "    return camera_params, points_3d, camera_indices, point_indices, points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params, points_3d, camera_indices, point_indices, points_2d = read_bal_data(FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have numpy arrays: \n",
    "\n",
    "1. `camera_params` with shape `(n_cameras, 9)` contains initial estimates of parameters for all cameras. First 3 components in each row form a rotation vector (https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula) corresponding to $\\pmb{R}$, next 3 components form a translation vector $\\pmb{t}$, then a focal distance and two distortion parameters.\n",
    "2. `points_3d` with shape `(n_points, 3)` contains initial estimates of point coordinates in the world frame.\n",
    "3. `camera_indices` with shape `(n_observations,)` contains indices of cameras (from 0 to `n_cameras - 1`) involved in each observation.\n",
    "4. `point_indices` with shape `(n_observations,)` contatins indices of points (from 0 to `n_points - 1`) involved in each observation.\n",
    "5. `points_2d` with shape `(n_observations, 2)` contains measured 2-D coordinates of points projected on images in each observations.\n",
    "\n",
    "In this dataset each image is taken from a different camera meaning that each camera has its own rotation, translation and optical parameters. \n",
    "Another typical scenario is when one camera is used to take images from different vantages, in this case we would estimate many rotation and translation parameters and one set of optical parameters.\n",
    "\n",
    "So in this dataset there is a one-to-one correspondence between cameras and images, such that you can think of \"camera index\" as of \"image index\".\n",
    "\n",
    "Let's output the problem's dimenstions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cameras: 49\n",
      "n_points: 7776\n",
      "Total number of parameters: 23769\n",
      "Total number of residuals: 63686\n"
     ]
    }
   ],
   "source": [
    "n_cameras = camera_params.shape[0]\n",
    "n_points = points_3d.shape[0]\n",
    "\n",
    "n = 9 * n_cameras + 3 * n_points\n",
    "m = 2 * points_2d.shape[0]\n",
    "\n",
    "print(\"n_cameras: {}\".format(n_cameras))\n",
    "print(\"n_points: {}\".format(n_points))\n",
    "print(\"Total number of parameters: {}\".format(n))\n",
    "print(\"Total number of residuals: {}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a relatively small problem to reduce computation time, but scipy's algorithm is capable of solving much larger problems, although required time will grow proportionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the function which returns a vector of residuals. \n",
    "To create a rotation transform we use `from_rotvec` method of `Rotation` class availble in `scipy.spatial.transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project(points, camera_params):\n",
    "    \"\"\"Convert 3-D points to 2-D by projecting onto images.\"\"\"\n",
    "    rotation = Rotation.from_rotvec(camera_params[:, :3])\n",
    "    points_camera = rotation.apply(points) + camera_params[:, 3:6]\n",
    "    points_proj = -points_camera[:, :2] / points_camera[:, 2, np.newaxis]\n",
    "    f = camera_params[:, 6]\n",
    "    k1 = camera_params[:, 7]\n",
    "    k2 = camera_params[:, 8]\n",
    "    n = np.sum(points_proj**2, axis=1)\n",
    "    r = 1 + k1 * n + k2 * n**2\n",
    "    points_proj *= (r * f)[:, np.newaxis]\n",
    "    return points_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(params, n_cameras, n_points, camera_indices, point_indices, points_2d):\n",
    "    \"\"\"Compute residuals.\n",
    "    \n",
    "    `params` contains camera parameters and 3-D coordinates.\n",
    "    \"\"\"\n",
    "    camera_params = params[:n_cameras * 9].reshape((n_cameras, 9))\n",
    "    points_3d = params[n_cameras * 9:].reshape((n_points, 3))\n",
    "    points_proj = project(points_3d[point_indices], camera_params[camera_indices])\n",
    "    return (points_proj - points_2d).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that computing Jacobian of `fun` is cumbersome, thus we will rely on the finite difference approximation. To make this process time feasible we provide Jacobian sparsity structure (i. e. mark elements which are known to be non-zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices):\n",
    "    m = camera_indices.size * 2\n",
    "    n = n_cameras * 9 + n_points * 3\n",
    "    A = lil_matrix((m, n), dtype=int)\n",
    "\n",
    "    i = np.arange(camera_indices.size)\n",
    "    for s in range(9):\n",
    "        A[2 * i, camera_indices * 9 + s] = 1\n",
    "        A[2 * i + 1, camera_indices * 9 + s] = 1\n",
    "\n",
    "    for s in range(3):\n",
    "        A[2 * i, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "        A[2 * i + 1, n_cameras * 9 + point_indices * 3 + s] = 1\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run optimization. \n",
    "We stack the camera parameters and the 3D point coordinates in a 1-dimensional vector, because it is expected by `least_squares` function.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.hstack((camera_params.ravel(), points_3d.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute sparsity structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = bundle_adjustment_sparsity(n_cameras, n_points, camera_indices, point_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally run the optimization with `least_squares` function. \n",
    "\n",
    "We set `scaling='jac'` to automatically scale the variables and equalize their influence on the cost function. This is necessary because we have 5 kind of parameters (rotation, translation, focal length, distortion and 3D coordinates) of completely different nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iteration     Total nfev        Cost      Cost reduction    Step norm     Optimality   \n",
      "       0              1         8.5091e+05                                    8.57e+06    \n",
      "       1              3         5.0985e+04      8.00e+05       1.46e+02       1.15e+06    \n",
      "       2              4         1.6077e+04      3.49e+04       2.59e+01       2.43e+05    \n",
      "       3              5         1.4163e+04      1.91e+03       2.86e+02       1.21e+05    \n",
      "       4              7         1.3695e+04      4.67e+02       1.32e+02       2.51e+04    \n",
      "       5              8         1.3481e+04      2.14e+02       2.24e+02       1.54e+04    \n",
      "       6              9         1.3436e+04      4.54e+01       3.18e+02       2.73e+04    \n",
      "       7             10         1.3422e+04      1.38e+01       6.79e+01       2.19e+03    \n",
      "       8             11         1.3418e+04      3.72e+00       1.31e+02       8.07e+03    \n",
      "       9             12         1.3414e+04      4.30e+00       2.62e+01       6.11e+02    \n",
      "      10             13         1.3412e+04      1.89e+00       7.68e+01       2.66e+03    \n",
      "      11             14         1.3410e+04      2.12e+00       1.76e+01       5.06e+02    \n",
      "      12             15         1.3409e+04      1.02e+00       3.98e+01       1.30e+03    \n",
      "`ftol` termination condition is satisfied.\n",
      "Function evaluations 15, initial cost 8.5091e+05, final cost 1.3409e+04, first-order optimality 1.30e+03.\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "res = least_squares(fun, x0, jac_sparsity=A, verbose=2, x_scale='jac', ftol=1e-4, method='trf',\n",
    "                    args=(n_cameras, n_points, camera_indices, point_indices, points_2d))\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization took 33 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimization took {0:.0f} seconds\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the optimization efficiency let's plot the reprojection errors (residual values) before and after the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun0 = fun(x0, n_cameras, n_points, camera_indices, point_indices, points_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(211)\n",
    "plt.plot(fun0)\n",
    "plt.title(\"Reprojection errors before optimization, RMS = {:.1f} pixels\".format(np.mean(fun0**2) ** 0.5))\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(res.fun)\n",
    "plt.title(\"Reprojection errors after optimization, RMS = {:.1f} pixels\".format(np.mean(res.fun**2) ** 0.5))\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We see significant improvements of the reprojection errors distribution and their RMS which indicates a successful optimization.\n",
    "\n",
    "The remaining spikes can be explained by some sort of inconsistency in the input data or a compromised convergence of the algorithm. The convergence issues might be caused by finite difference approximation of the Jacobian."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Suggested excersises for the reader:\n",
    "\n",
    "1. Implement analytical Jacobian computation and see if it improves the final cost function and removes the spikes.\n",
    "2. Try to reduce the final cost function by adjusting the algorithm's parameters.\n",
    "3. Visualize 3D point clouds before and after optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}